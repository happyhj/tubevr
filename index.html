<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Connecting up Google Cardboard to web APIs</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
    <style>
      body {
        margin: 0px;
        overflow: hidden;
      }
      #webglviewer {
        bottom: 0;
        left: 0;
        position: absolute;
        right: 0;
        top: 0;
      }
      button {
	      position: fixed;
	      top:0;
	      left: 0;
      }
    </style>
  </head>
  <body>
	<video id="video" src="cocvr.mp4"></video>

    <div id="webglviewer">
<button id="play">Play</button>
<button id="pause">Pause</button>
<button id="load">Load</button>
    </div>

    <script src="./js/three.min.js"></script>
    <script src="./js/StereoEffect.js"></script>
    <script src="./js/DeviceOrientationControls.js"></script>
    <script src="./js/OrbitControls.js"></script>
<script>
function InlineVideo(videoSrc, wrapEl) {
  this.wrapEl = wrapEl || document.body;

  this.videlEl = document.createElement('video');
  this.wrapEl.appendChild(this.videlEl)
  this.videlEl.src = videoSrc;

  this.audioEl = document.createElement("audio");
  this.wrapEl.appendChild(this.audioEl)
  this.audioEl.src = videoSrc;
  
  this._loopProperty = {
    lastTime: null,
    animationFrame: null,
    framesPerSecond: 60
  };
}

InlineVideo.prototype.load = function() {
  this.videlEl.load();
  this.audioEl.load();
};

InlineVideo.prototype.play = function() {
  this.audioEl.play();
  this._loopProperty.lastTime = Date.now();
  this._loop();
};

InlineVideo.prototype.pause = function() {
  this.audioEl.pause()
  window.cancelAnimationFrame(this._loopProperty.animationFrame);
}

InlineVideo.prototype._loop = function() {
    var time = Date.now();
    var elapsed = (time - this._loopProperty.lastTime) / 1000;
    // render
    if(elapsed >= ((1000/this._loopProperty.framesPerSecond)/1000)) { 
      console.log(this.audioEl.currentTime)
      this.videlEl.currentTime = this.audioEl.currentTime;
      this._loopProperty.lastTime = time;
    }

    // if we are at the end of the video stop
    var currentTime = (Math.round(parseFloat(this.videlEl.currentTime)*10000)/10000);
    var duration = (Math.round(parseFloat(this.videlEl.duration)*10000)/10000);
    if(currentTime >= duration) {
        console.log('currentTime: ' + currentTime + ' duration: ' + this.videlEl.duration);
        window.cancelAnimationFrame(this._loopProperty.animationFrame);
        this.load();
      return;
    }

    this._loopProperty.animationFrame = requestAnimationFrame(this._loop.bind(this));
};	
</script>
	<script>
		
var THREEx = THREEx || {}

THREEx.VideoTexture	= function(video){
	// create the texture
	var texture	= new THREE.Texture( video );
	// expose texture as this.texture
	this.texture	= texture

	/**
	 * update the object
	 */
	this.update	= function(){
		if( video.readyState !== video.HAVE_ENOUGH_DATA )	return;
		texture.needsUpdate	= true;		
	}
}
	</script>

    <script>
      var scene,
          camera, 
          renderer,
          element,
          container,
          effect,
          controls,
          clock,
          updateFcts;
          
		  var inlineVideo = new InlineVideo("cocvr.mp4");
      
        init();

      function init() {
 	    updateFcts	= [];
        scene = new THREE.Scene();
        camera = new THREE.PerspectiveCamera(90, window.innerWidth / window.innerHeight, 0.001, 700);
		camera	= new THREE.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 0.001, 700 );
        scene.add(camera);

        renderer = new THREE.WebGLRenderer({
	        antialias	: true
	    });
        element = renderer.domElement;
    	renderer.setClearColor(new THREE.Color('lightgrey'), 1)
		renderer.setSize( window.innerWidth, window.innerHeight );
        
        container = document.getElementById('webglviewer');
        container.appendChild(element);

        effect = new THREE.StereoEffect(renderer);

        // Our initial control fallback with mouse/touch events in case DeviceOrientation is not enabled
        controls = new THREE.OrbitControls(camera, element);
        controls.target.set(
          camera.position.x + 0.15,
          camera.position.y,
          camera.position.z
        );
        controls.noPan = true;
        controls.noZoom = true;


		/* 구 와 비디오 텍스처 추가하기 */
		// find out which file formats i can read
		var url = 'cocvr.mp4';

		// create the videoTexture
		videoTexture = new THREEx.VideoTexture(inlineVideo.videlEl)
		
		updateFcts.push(function(delta, now){
			videoTexture.update(delta, now)
		})
		
		// use the texture in a THREE.Mesh
		var geometry   = new THREE.SphereGeometry(10, 32, 32)
		
		//	var geometry	= new THREE.CubeGeometry(1,1,1);
		var material	= new THREE.MeshBasicMaterial({
			map	: videoTexture.texture,
			side: THREE.BackSide
		});
		var sphere	= new THREE.Mesh( geometry, material );
		scene.add( sphere );
		


        // Our preferred controls via DeviceOrientation
        function setOrientationControls(e) {
          if (!e.alpha) {
            return;
          }

          controls = new THREE.DeviceOrientationControls(camera, true);
          controls.connect();
          controls.update();

          element.addEventListener('click', fullscreen, false);

          window.removeEventListener('deviceorientation', setOrientationControls, true);
        }
        window.addEventListener('deviceorientation', setOrientationControls, true);

        clock = new THREE.Clock();

        animate();
      }

      function animate(nowMsec) {
        var elapsedSeconds = clock.getElapsedTime();
        requestAnimationFrame(animate);

        update(clock.getDelta(), nowMsec);
        render(clock.getDelta());
      }

      function resize() {
        var width = container.offsetWidth;
        var height = container.offsetHeight;

        camera.aspect = width / height;
        camera.updateProjectionMatrix();

        renderer.setSize(width, height);
        effect.setSize(width, height);
      }
      
	  var lastTimeMsec = null;
      function update(dt, nowMsec) {
        resize();

        camera.updateProjectionMatrix();

        controls.update(dt);
		// measure time
		lastTimeMsec	= lastTimeMsec || nowMsec-1000/60
		var deltaMsec	= Math.min(200, nowMsec - lastTimeMsec)
		lastTimeMsec	= nowMsec
		// call each update function
		updateFcts.forEach(function(updateFn){
			updateFn(deltaMsec/1000, nowMsec/1000)
		})
      }

      function render(dt) {
        //effect.render(scene, camera);
		renderer.render( scene, camera );
      }

      function fullscreen() {
        if (container.requestFullscreen) {
          container.requestFullscreen();
        } else if (container.msRequestFullscreen) {
          container.msRequestFullscreen();
        } else if (container.mozRequestFullScreen) {
          container.mozRequestFullScreen();
        } else if (container.webkitRequestFullscreen) {
          container.webkitRequestFullscreen();
        }
      }
      

// video 컴포넌트 재생하기만 하면됨
var loadBtn = document.getElementById("load");
loadBtn.addEventListener("click", function() {
  inlineVideo.load();
});

var playBtn = document.getElementById("play");
playBtn.addEventListener("click", function() {
  inlineVideo.play();
});

var pauseBtn = document.getElementById("pause");
pauseBtn.addEventListener("click", function() {
  inlineVideo.pause();
});
    </script>
  </body>
</html>
